def extract_statements_with_llm_discovery(full_text,
                                          session_id,
                                          known_bill_names,
                                          session_obj,
                                          debug=False):
    """
    Uses a single, powerful LLM call to:
    1. Find discussion segments for a list of known bills.
    2. Discover and segment any additional bills/topics discussed in the text.
    3. Creates placeholder bills for newly discovered items.
    """
    logger = logging.getLogger(__name__)
    logger.info(
        f"ğŸ¤– Starting LLM discovery and segmentation for session: {session_id}")

    if not reinitialize_gemini():
        logger.error("âŒ Gemini not available. Cannot perform LLM discovery.")
        return []

    # Prepare the list of known bills for the prompt
    if known_bill_names:
        known_bills_str = "\n".join(f"- {name}" for name in known_bill_names)
    else:
        known_bills_str = "No known bills were provided."

    prompt = f"""You are a world-class legislative analyst AI. Your task is to read a parliamentary transcript
and perfectly segment the entire discussion for all topics, while also analyzing policy content.

**CONTEXT:**
I already know about the following bills. You MUST find the discussion for these if they exist.
--- KNOWN BILLS ---
{known_bills_str}

**YOUR CRITICAL MISSION:**
1. Read the entire transcript below.
2. Identify the exact start and end character index for the complete discussion of each **KNOWN BILL**.
3. Discover any additional bills/topics not in the known list, and identify their discussion spans.
4. For each bill/topic, analyze the policy content and categorize it.
5. Return a JSON object with segmentation AND policy analysis.

**POLICY CATEGORIES:**
- ê²½ì œ/ì‚°ì—…: ê²½ì œì •ì±…, ì‚°ì—…ì§„í¥, ê¸ˆìœµ, ë¬´ì—­, ì¤‘ì†Œê¸°ì—…, ë²¤ì²˜
- ì‚¬íšŒë³µì§€: ë³µì§€ì •ì±…, ì‚¬íšŒë³´ì¥, ì˜ë£Œë³´í—˜, ì—°ê¸ˆ, ëŒë´„ì„œë¹„ìŠ¤
- êµìœ¡/ë¬¸í™”: êµìœ¡ì •ì±…, ëŒ€í•™, ë¬¸í™”ì˜ˆìˆ , ì²´ìœ¡, ê´€ê´‘
- í™˜ê²½/ì—ë„ˆì§€: í™˜ê²½ë³´í˜¸, ê¸°í›„ë³€í™”, ì‹ ì¬ìƒì—ë„ˆì§€, ì›ìë ¥
- êµ­ë°©/ì™¸êµ: êµ­ë°©ì •ì±…, ì™¸êµê´€ê³„, í†µì¼, ì•ˆë³´
- í–‰ì •/ë²•ë¬´: í–‰ì •ê°œí˜, ì‚¬ë²•ì œë„, ì¸ê¶Œ, ê°œì¸ì •ë³´ë³´í˜¸
- ê³¼í•™ê¸°ìˆ : ê³¼í•™ê¸°ìˆ ì§„í¥, IT, ë””ì§€í„¸ì „í™˜, ì¸ê³µì§€ëŠ¥
- ë†ë¦¼/í•´ì–‘: ë†ì—…, ì„ì—…, ìˆ˜ì‚°ì—…, ë†ì´Œê°œë°œ
- êµ­í† /êµí†µ: êµ­í† ê°œë°œ, êµí†µì •ì±…, ì£¼íƒ, ë„ì‹œê³„íš
- ë³´ê±´/ì˜ë£Œ: ë³´ê±´ì •ì±…, ì˜ë£Œì„œë¹„ìŠ¤, ì§ˆë³‘ê´€ë¦¬, ê±´ê°•ì¦ì§„

**RULES:**
- Ignore any mentions that occur in the table-of-contents or front-matter portion of the document
  (before the Chair officially opens the debate).
- A discussion segment **must** be substantive, containing actual debate or remarks from multiple speakers.
  Do not segment short procedural announcements.
- `bill_name` for known bills MUST EXACTLY MATCH the provided list.
- For new items, create a concise, accurate `bill_name`.
- Analyze policy content for each segment and assign appropriate categories.
- Extract key policy phrases and specific keywords related to the bill.
- Return **ONLY** the final JSON object.

**TRANSCRIPT:**
---
{full_text}
---

**REQUIRED JSON OUTPUT FORMAT:**
{{
  "bills_found": [
    {{
      "bill_name": "Exact name of a KNOWN bill",
      "start_index": 1234,
      "end_index": 5678,
      "policy_categories": ["ê²½ì œ/ì‚°ì—…", "ì‚¬íšŒë³µì§€"],
      "key_policy_phrases": ["ì¤‘ì†Œê¸°ì—… ì§€ì›", "ì¼ìë¦¬ ì°½ì¶œ", "ì‚¬íšŒì•ˆì „ë§"],
      "bill_analysis": ["ddddí•˜ëŠ” ì˜ì•ˆì…ë‹ˆë‹¤."]
    }}
    // â€¦more known bills
  ],
  "newly_discovered": [
    {{
      "bill_name": "Name of a newly discovered topic",
      "start_index": 2345,
      "end_index": 6789,
      "policy_categories": ["í™˜ê²½/ì—ë„ˆì§€"],
      "key_policy_phrases": ["íƒ„ì†Œì¤‘ë¦½", "ì¬ìƒì—ë„ˆì§€"],
      "bill_analysis": ["ddddí•˜ëŠ” ì˜ì•ˆì…ë‹ˆë‹¤."]
    }}
    // â€¦more new topics
  ]
}}
"""
    try:
        segmentation_model = genai.GenerativeModel(
            'gemini-2.5-flash-preview-05-20')
        estimated_tokens = len(prompt) // 3

        if not gemini_rate_limiter.wait_if_needed(estimated_tokens):
            logger.error("Rate limit timeout for LLM discovery. Aborting.")
            return []

        response = segmentation_model.generate_content(prompt)
        gemini_rate_limiter.record_request(estimated_tokens, success=True)

        # Strip markdown fences if present
        response_text = response.text.strip()
        if response_text.startswith("```"):
            response_text = response_text.split("```", 2)[-1].strip()

        data = json.loads(response_text)
        if not isinstance(data, dict):
            logger.error("LLM discovery did not return a JSON object.")
            return []

        # Merge the two arrays into one flat list, tagging each entry
        all_segments = []

        for seg in data.get("bills_found", []):
            seg["is_newly_discovered"] = False
            all_segments.append(seg)

        for seg in data.get("newly_discovered", []):
            seg["is_newly_discovered"] = True
            all_segments.append(seg)

        logger.info(
            f"âœ… LLM segmented {len(all_segments)} total discussion topics.")

        # Create placeholders for newly discovered bills with policy analysis
        if not debug:
            for segment in all_segments:
                if segment.get("is_newly_discovered"):
                    bill_obj = create_placeholder_bill_from_llm(session_obj,
                                                               segment["bill_name"])
                    # Update bill with policy analysis from segmentation
                    if bill_obj:
                        update_bill_policy_data(bill_obj, segment)

        # Process each segment to extract statements and update policy data
        all_statements = []
        for segment in sorted(all_segments,
                              key=lambda x: x.get('start_index', 0)):
            bill_name = segment.get("bill_name")
            start = segment.get("start_index", 0)
            end = segment.get("end_index", 0)

            if not bill_name or end <= start:
                continue

            # Update policy data for known bills as well
            if not debug and not segment.get("is_newly_discovered"):
                try:
                    # Find the existing bill and update its policy data
                    existing_bill = Bill.objects.filter(
                        session=session_obj,
                        bill_nm__iexact=bill_name
                    ).first()
                    if existing_bill:
                        update_bill_policy_data(existing_bill, segment)
                except Exception as e:
                    logger.warning(f"Could not update policy data for known bill '{bill_name}': {e}")

            segment_text = full_text[start:end]
            logger.info(
                f"--- Processing segment for: '{bill_name}' (Chars {start}-{end}) ---"
            )

            statements_in_segment = extract_statements_for_bill_segment(
                segment_text, session_id, bill_name, debug)

            # Associate these statements with the correct bill name and policy data
            for stmt in statements_in_segment:
                stmt['associated_bill_name'] = bill_name
                # Add policy context to statements
                stmt['policy_categories'] = segment.get('policy_categories', [])
                stmt['policy_keywords'] = segment.get('key_policy_phrases', [])
                stmt['bill_specific_keywords'] = segment.get('bill_specific_keywords', [])

            all_statements.extend(statements_in_segment)

        return all_statements

    except Exception as e:
        gemini_rate_limiter.record_error("llm_discovery_error")
        logger.error(
            f"âŒ Critical error during LLM discovery and segmentation: {e}")
        logger.exception("Full traceback for LLM discovery:")
        return []
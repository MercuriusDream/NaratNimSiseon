
from django.core.management.base import BaseCommand
from django.conf import settings
import os

class Command(BaseCommand):
    help = 'Test new Gemini library format from Google GenAI'

    def add_arguments(self, parser):
        parser.add_argument(
            '--test-simple',
            action='store_true',
            help='Run a simple test with the new library',
        )
        parser.add_argument(
            '--test-llm-discovery',
            action='store_true',
            help='Test the LLM discovery functionality',
        )

    def handle(self, *args, **options):
        test_simple = options.get('test_simple', False)
        test_llm_discovery = options.get('test_llm_discovery', False)

        self.stdout.write('ğŸ§ª Testing new Google GenAI library format...')

        # Check API key
        if not hasattr(settings, 'GEMINI_API_KEY') or not settings.GEMINI_API_KEY:
            self.stdout.write(
                self.style.ERROR('âŒ GEMINI_API_KEY not found in settings')
            )
            return

        self.stdout.write(f'âœ… API Key found: {settings.GEMINI_API_KEY[:10]}...')

        # Test import of new library
        try:
            from google import genai
            from google.genai import types
            self.stdout.write('âœ… google.genai imported successfully')
        except ImportError as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ Failed to import google.genai: {e}')
            )
            self.stdout.write('ğŸ’¡ You may need to install: pip install google-genai')
            return

        # Test client initialization
        try:
            client = genai.Client(api_key=settings.GEMINI_API_KEY)
            self.stdout.write('âœ… GenAI client initialized successfully')
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ Failed to initialize client: {e}')
            )
            return

        if test_simple:
            self.test_simple_generation(client)
        elif test_llm_discovery:
            self.test_llm_discovery_format(client)
        else:
            self.stdout.write('Use --test-simple or --test-llm-discovery to run specific tests')

    def test_simple_generation(self, client):
        """Test simple text generation with new library"""
        try:
            from google.genai import types
            
            self.stdout.write('ğŸ”„ Testing simple text generation...')
            
            model = "gemini-2.5-flash-preview-05-20"
            contents = [
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_text(text="ì•ˆë…•í•˜ì„¸ìš”. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì§§ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.")
                    ],
                ),
            ]
            
            config = types.GenerateContentConfig(
                response_mime_type="text/plain",
            )
            
            response_text = ""
            for chunk in client.models.generate_content_stream(
                model=model,
                contents=contents,
                config=config,
            ):
                response_text += chunk.text
            
            if response_text:
                self.stdout.write(f'âœ… Generation successful: {response_text[:200]}...')
            else:
                self.stdout.write('âŒ No response text generated')
                
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ Simple generation failed: {e}')
            )

    def test_llm_discovery_format(self, client):
        """Test the LLM discovery format from your attached code"""
        try:
            from google.genai import types
            
            self.stdout.write('ğŸ”„ Testing LLM discovery format...')
            
            # Sample Korean parliamentary text for testing
            sample_text = """
(14ì‹œ09ë¶„ ê°œì˜)
â—¯ì˜ì¥ ìš°ì›ì‹ ì˜ì„ì„ ì •ëˆí•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.
ì„±ì›ì´ ë˜ì—ˆìœ¼ë¯€ë¡œ ì œ1ì°¨ ë³¸íšŒì˜ë¥¼ ê°œì˜í•˜ê² ìŠµë‹ˆë‹¤.

1. ê²€ì‚¬ì§•ê³„ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ(ê¹€ìš©ë¯¼ ì˜ì› ëŒ€í‘œë°œì˜)(ì˜ì•ˆë²ˆí˜¸ 2208456)

â—¯ê¹€ìš©ë¯¼ ì˜ì› ê²€ì‚¬ì§•ê³„ë²• ê°œì •ì•ˆì— ëŒ€í•´ì„œ ì°¬ì„±í•˜ëŠ” ì…ì¥ì„ ë°íˆê³ ì í† ë¡ ì— ì„í•˜ê²Œ ëìŠµë‹ˆë‹¤.
ê²€ì‚¬ê°€ ì˜ëª»í•˜ë©´ ëˆ„ê°€ ì§•ê³„ë¥¼ í•˜ê³  ëˆ„ê°€ ê°ì°°í•˜ê³  ëˆ„ê°€ ìˆ˜ì‚¬í•˜ëŠ”ì§€ ì•„ì‹­ë‹ˆê¹Œ? ì˜¤ë¡œì§€ ê²€ì‚¬ë§Œ í•´ ì™”ìŠµë‹ˆë‹¤.
            """
            
            model = "gemini-2.5-flash-preview-05-20"
            contents = [
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_text(text=f"""You are a world-class legislative analyst AI. 

**KNOWN BILLS:**
- ê²€ì‚¬ì§•ê³„ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ(ê¹€ìš©ë¯¼ ì˜ì› ëŒ€í‘œë°œì˜)(ì˜ì•ˆë²ˆí˜¸ 2208456)

**TRANSCRIPT:**
---
{sample_text}
---

**REQUIRED JSON OUTPUT FORMAT:**
{{
  "bills_found": [
    {{
      "bill_name": "ê²€ì‚¬ì§•ê³„ë²• ì¼ë¶€ê°œì •ë²•ë¥ ì•ˆ(ê¹€ìš©ë¯¼ ì˜ì› ëŒ€í‘œë°œì˜)(ì˜ì•ˆë²ˆí˜¸ 2208456)",
      "start_index": 123,
      "end_index": 456,
      "main_policy_category": "ë²•í–‰ì •ì œë„",
      "policy_subcategories": ["ê²€ì°° ê°œí˜"],
      "key_policy_phrases": ["ê²€ì°°ì— ëŒ€í•œ ë¯¼ì£¼ì  í†µì œ", "ê²€ì‚¬ ì§•ê³„"],
      "bill_specific_keywords": ["ê²€ì‚¬ì§•ê³„ë²•", "ë²•ë¬´ë¶€ì¥ê´€", "ì§•ê³„ì²­êµ¬"],
      "policy_stance": "progressive",
      "bill_analysis": "ê²€ì°°ì— ëŒ€í•œ ë¯¼ì£¼ì  í†µì œ ê°•í™”ë¥¼ ìœ„í•œ ì§•ê³„ì œë„ ê°œì„ "
    }}
  ],
  "newly_discovered": []
}}"""),
                    ],
                ),
            ]
            
            config = types.GenerateContentConfig(
                response_mime_type="text/plain",
            )
            
            response_text = ""
            for chunk in client.models.generate_content_stream(
                model=model,
                contents=contents,
                config=config,
            ):
                response_text += chunk.text
            
            if response_text:
                self.stdout.write(f'âœ… LLM Discovery test successful!')
                self.stdout.write(f'ğŸ“„ Response length: {len(response_text)} characters')
                self.stdout.write(f'ğŸ“ Sample response: {response_text[:300]}...')
                
                # Try to parse as JSON
                try:
                    import json
                    # Clean response
                    clean_response = response_text.strip()
                    if clean_response.startswith("```"):
                        clean_response = clean_response.split("```", 2)[-1].strip()
                    
                    parsed_json = json.loads(clean_response)
                    self.stdout.write(f'âœ… Response is valid JSON with {len(parsed_json.get("bills_found", []))} bills found')
                except json.JSONDecodeError as e:
                    self.stdout.write(f'âš ï¸ Response is not valid JSON: {e}')
            else:
                self.stdout.write('âŒ No response text generated')
                
        except Exception as e:
            self.stdout.write(
                self.style.ERROR(f'âŒ LLM Discovery test failed: {e}')
            )

        self.stdout.write(
            self.style.SUCCESS('ğŸ‰ New GenAI library test completed!')
        )
